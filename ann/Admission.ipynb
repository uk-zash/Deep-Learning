{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Admission_Predict_Ver1.1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Serial No.\"] , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          500 non-null    int64  \n",
      " 1   TOEFL Score        500 non-null    int64  \n",
      " 2   University Rating  500 non-null    int64  \n",
      " 3   SOP                500 non-null    float64\n",
      " 4   LOR                500 non-null    float64\n",
      " 5   CGPA               500 non-null    float64\n",
      " 6   Research           500 non-null    int64  \n",
      " 7   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 31.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0        337          118                  4  4.5   4.5  9.65         1\n",
       "1        324          107                  4  4.0   4.5  8.87         1\n",
       "2        316          104                  3  3.0   3.5  8.00         1\n",
       "3        322          110                  3  3.5   2.5  8.67         1\n",
       "4        314          103                  2  2.0   3.0  8.21         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[: , :-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[: , -1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test, y_train , y_test = train_test_split(X , y , test_size = 0.2 , random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>328</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>313</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>322</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>320</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>321</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>317</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>315</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "12         328          112                  4  4.0   4.5  9.10         1\n",
       "199        313          107                  3  4.0   4.5  8.69         0\n",
       "488        322          112                  3  3.0   4.0  8.62         1\n",
       "231        319          106                  3  3.5   2.5  8.33         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "277        320          101                  2  2.5   3.0  8.62         0\n",
       "305        321          109                  3  3.5   3.5  8.80         1\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "320        317          106                  3  4.0   3.5  8.50         1\n",
       "324        315          104                  3  3.0   2.5  8.33         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76      , 0.71428571, 0.75      , ..., 0.875     , 0.73954984,\n",
       "        1.        ],\n",
       "       [0.46      , 0.53571429, 0.5       , ..., 0.875     , 0.60771704,\n",
       "        0.        ],\n",
       "       [0.64      , 0.71428571, 0.5       , ..., 0.75      , 0.585209  ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.34      , 0.64285714, 0.75      , ..., 0.875     , 0.50482315,\n",
       "        0.        ],\n",
       "       [0.54      , 0.5       , 0.5       , ..., 0.625     , 0.54662379,\n",
       "        1.        ],\n",
       "       [0.5       , 0.42857143, 0.5       , ..., 0.375     , 0.49196141,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7 , activation= \"relu\" , input_dim = 7))\n",
    "\n",
    "model.add(Dense(1 , activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64 (256.00 Byte)\n",
      "Trainable params: 64 (256.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"mean_squared_error\" , optimizer=\"Adam\" , metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 25ms/step - loss: 0.4292 - accuracy: 0.0000e+00 - val_loss: 0.3706 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3560 - accuracy: 0.0000e+00 - val_loss: 0.3026 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2885 - accuracy: 0.0000e+00 - val_loss: 0.2403 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2264 - accuracy: 0.0000e+00 - val_loss: 0.1877 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1747 - accuracy: 0.0000e+00 - val_loss: 0.1479 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1218 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.0000e+00 - val_loss: 0.1063 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.0000e+00 - val_loss: 0.0976 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0964 - accuracy: 0.0000e+00 - val_loss: 0.0922 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0911 - accuracy: 0.0000e+00 - val_loss: 0.0873 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0857 - accuracy: 0.0000e+00 - val_loss: 0.0828 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0808 - accuracy: 0.0000e+00 - val_loss: 0.0782 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.0000e+00 - val_loss: 0.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.0000e+00 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0648 - accuracy: 0.0000e+00 - val_loss: 0.0604 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0566 - accuracy: 0.0000e+00 - val_loss: 0.0521 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.0000e+00 - val_loss: 0.0408 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0311 - accuracy: 0.0000e+00 - val_loss: 0.0314 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0183 - accuracy: 0.0000e+00 - val_loss: 0.0203 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 0.0000e+00 - val_loss: 0.0173 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 0.0000e+00 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0139 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0128 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled , y_train , epochs = 100 , validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7983072291207914"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1787daa8390>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
